# Desenvolvimento da aplica√ß√£o [*"EmotePet API"*]

## üë®‚Äçüíª Projeto desenvolvido por: [Brenno Ostemberg](https://github.com/brenno-ostemberg), [Jos√© Pedro C√¢ndido L.P.](https://github.com/PeterYouseph), [Rafael Torres Nantes](https://github.com/rafael-torres-nantes) e [Sarah Baraldi](https://github.com/mbaraldi-sarah).

## √çndice

* [üìö Contextualiza√ß√£o do projeto](#-contextualiza√ß√£o-do-projeto)
* [üõ†Ô∏è Tecnologias/Ferramentas utilizadas](#%EF%B8%8F-tecnologiasferramentas-utilizadas)
* [üñ•Ô∏è Funcionamento do sistema](#%EF%B8%8F-funcionamento-do-sistema)
   * [üòÅ Parte 1 - Emo√ß√µes](#-parte-1---emo√ß√µes)
   * [üê∂ Parte 2 - Emo√ß√µes e Pets](#-parte-2---emo√ß√µes-e-pets)
   * [‚òÅÔ∏è Inserindo logs no Cloudwatch](#%EF%B8%8F-inserindo-logs-no-cloudwatch)
   * [üîÄ Fluxo da aplica√ß√£o](#em-resumo-o-fluxo-da-aplica√ß√£o-se-d√°-da-seguinte-forma)
* [üìÅ Estrutura do projeto](#-estrutura-do-projeto)
* [üìå Como executar o projeto](#-como-executar-o-projeto)
* [üîó Endpoints](#-endpoints)
* [üïµÔ∏è Dificuldades Encontradas](#%EF%B8%8F-dificuldades-encontradas)

## üìö Contextualiza√ß√£o do projeto

O projeto tem o objetivo de criar uma API que receba imagens postadas no *AWS S3*, utilize o *Amazon Rekognition* identificar bichos e humanos, utilize o *Amazon Bedrock* para extrair dicas de como cuidar dos pets reconhecidos e grave os *logs* dos resultados utilizando *CloudWatch*.


## üõ†Ô∏è Tecnologias/Ferramentas utilizadas

[<img src="https://img.shields.io/badge/Visual_Studio_Code-007ACC?logo=visual-studio-code&logoColor=white">](https://code.visualstudio.com/)
[<img src="https://img.shields.io/badge/Git-232F3E?logo=git&logoColor=red">](https://git-scm.com/)
[<img src="https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=violet">](https://github.com/)
[<img src="https://img.shields.io/badge/AWS-fda100?logo=amazon-aws&logoColor=white">](https://aws.amazon.com/pt/)
[<img src="https://img.shields.io/badge/AWS-CLI-232F3E?logo=amazon-aws&logoColor=white">](https://aws.amazon.com/pt/cli/)
[<img src="https://img.shields.io/badge/AWS-S3-dd2304?logo=amazon-aws&logoColor=white">](https://aws.amazon.com/pt/s3/)
[<img src="https://img.shields.io/badge/AWS-Cloudwatch-green?logo=amazon-aws&logoColor=white">](https://aws.amazon.com/pt/cloudwatch/)
[<img src="https://img.shields.io/badge/Amazon-Bedrock-01ac71?logo=amazon-aws&logoColor=white">](https://aws.amazon.com/pt/bedrock/)
[<img src="https://img.shields.io/badge/Amazon-Rekognition-blue?logo=amazon-aws&logoColor=white">](https://aws.amazon.com/pt/rekognition/)
[<img src="https://img.shields.io/badge/Serverless_Framework-ff5242?logo=amazon-aws&logoColor=white">](https://www.serverless.com)

#### Organiza√ß√£o do Time:

[<img src="https://img.shields.io/badge/Trello-0079BF?logo=trello&logoColor=white">](https://trello.com/)
[<img src="https://img.shields.io/badge/Teams-6264A7?logo=microsoft-teams&logoColor=white">](https://www.microsoft.com/pt-br/microsoft-teams/group-chat-software)

## üñ•Ô∏è Funcionamento do sistema

### üòÅ Parte 1 - Emo√ß√µes

Utilizando o *framework* **Serverless**, enviamos um *json* via **POST** √† rota [`/v1/vision`](https://fbpdfs3097.execute-api.us-east-1.amazonaws.com/v1/vision), onde utilizamos o **Amazon Rekognition** para detectar as faces e emo√ß√µes. Al√©m disso, s√£o efetuados *logs* referentes a cada solita√ß√£o no **AWS Cloudwatch**.

#### Exemplo de entrada:

```json 
{ 
   "bucket": "nomeBucket", 
   "imageName": "nomeFoto.jpg" 
} 
```

Ou

```json 
{
   "body": {
      "bucket": "sprint08-my-photos",
      "imageName": "Fofos.png"
   }
}
```

#### Exemplos de Sa√≠da:

1. Caso haja apenas uma face:

```json 
{
   "url_to_image": "https://sprint08-my-photos.s3.amazonaws.com/FaceOne.jpg", 
   "created_image": "02-07-2024 00:51:03", 
   "faces": [
      {
         "position": {
            "Height": 0.2435552030801773, 
            "Left": 0.6044005751609802, 
            "Top": 0.15545067191123962, 
            "Width": 0.17254146933555603
         }, 
         "classified_emotion": "HAPPY", 
         "classified_emotion_confidence":¬†100.0
      }
   ]
}
```

2. Caso haja mais de uma face, o elemento *"faces": [{...}]* recebe mais de um objeto:

```json
{
   "url_to_image": "https://sprint08-my-photos.s3.amazonaws.com/Faces_1.jpg", 
   "created_image": "02-07-2024 00:51:05", 
   "faces": [
      {
         "position": {
            "Height": 0.7969402074813843, 
            "Left": 0.1317732036113739, 
            "Top": 0.06133376806974411, 
            "Width": 0.3078056275844574
         }, 
         "classified_emotion": "HAPPY", 
         "classified_emotion_confidence": 100.0
      }, 
      {
         "position": {
            "Height": 0.7686970233917236, 
            "Left": 0.5813419818878174, 
            "Top": 0.0527547188103199, 
            "Width": 0.3050912320613861
         }, 
         "classified_emotion": "CALM", 
         "classified_emotion_confidence":¬†93.5546875
      }
   ]
}
```

3. Caso **N√ÉO** haja faces, os elementos contidos em *"faces": [{...}]* recebem valor *None*:

```json 
{
   "url_to_image": "https://sprint08-my-photos.s3.amazonaws.com/Bola.jpg", 
   "created_image": "02-07-2024 00:54:10", 
   "faces": [
      {
         "position": {
            "Height": None, 
            "Left": None, 
            "Top": None, 
            "Width": None
         }, 
         "classified_emotion": None, 
         "classified_emotion_confidence":¬†None
      }
   ]
}
``` 

#### Detectando elementos:

- **Detectando as *faces***: utilizamos a fun√ß√£o `detect_faces` da seguinte forma:

```py
response = self.rekognition.detect_faces(
   Image={
      "S3Object": {
         "Bucket": bucket,
         "Name": image_name
      }
   },
   Attributes=["ALL"]
)
```

- **Detectando as *emo√ß√µes***: utilizamos a fun√ß√£o `detect_labels` da seguinte forma:

```py
response = self.rekognition.detect_labels(
   Image={
      "S3Object": {
         "Bucket": bucket,
         "Name": image_name
      }
   },
   MaxLabels=10,
   MinConfidence=80
)
```

### üê∂ Parte 2 - Emo√ß√µes e Pets

De maneira an√°loga √† Parte 1, desenvolvemos o sistema utilizamos o *framework* **Serverless** para enviarmos um *json* via **POST** √† rota [`/v2/vision`](https://fbpdfs3097.execute-api.us-east-1.amazonaws.com/v2/vision), onde utilizamos o **Amazon Rekognition** para detectar os pets, suas emo√ß√µes e ra√ßas. Al√©m disso, utilizamos o **Amazon Bedrock** para receber **dicas** de cuidados para cada ra√ßa dos pets reconhecidos. Por fim, s√£o efetuados *logs* referentes a cada solita√ß√£o no **AWS Cloudwatch**.

#### Exemplo de entrada:

```json 
{
   "bucket": "sprint08-my-photos", 
   "imageName": "Fofos.png"
}
```

Ou

```json 
{
   "body": {
      "bucket": "sprint08-my-photos",
      "imageName": "Fofos.png"
   }
}
```

#### Exemplos de Sa√≠da:

1. Caso haja **apenas um pet**:

```json 
{
   "url_to_image": "https://sprint08-my-photos.s3.amazonaws.com/Fofos.png",
   "created_image": "01-07-2024 01:25:36", 
   "faces": [
      {
         "position":
         {
            "Height": null, 
            "Left": null, 
            "Top": null, 
            "Width": null
         }, 
         "classified_emotion": null, 
         "classified_emotion_confidence": null
      }
   ], 
   "pets": [
      {
         "labels": [
            {
               "Confidence": 98.87677001953125, 
               "Name": "Puppy"
            }
         ], 
         "Dicas": "O Puppy √© um pet inteligente e alegre que gosta de jogar e ser socializado. Ele tem um n√≠vel de energia alto e necessita de atividade regular para mant√™-lo saud√°vel. O temperamento de Puppy √© amig√°vel e carinhoso, ele √© facilmente trainado e pode ser adaptado a diferentes ambientes. Os cuidados de Puppy incluem alimenta√ß√£o balanceada, higiene regular, exames regulares com o veterin√°rio,¬†vacina"
      }
   ]
}
```

2. Caso haja **uma pessoa e um pet**, retorna uma resposta como √† da Parte 1, e tamb√©m informa√ß√µes de pet, como no exemplo anterior:

```json
{
   "url_to_image": "https://sprint08-my-photos.s3.amazonaws.com/Faces_And_Dog.jpg",
   "created_image": "02-07-2024 00:51:03", 
   "faces": [
      {
         "position": {
            "Height": 0.2435552030801773, 
            "Left": 0.6044005751609802, 
            "Top": 0.15545067191123962, 
            "Width": 0.17254146933555603
         }, 
         "classified_emotion": "HAPPY", 
         "classified_emotion_confidence": 100.0
      }
   ], 
   "pets": [
      {
         "labels": [
            {
               "Confidence": 99.94889831542969, 
               "Name": "Golden Retriever"
            }
         ], 
         "Dicas": "\nDicas sobre Golden Retriever: \n\n- N√≠vel de Energia e Necessidades de Exerc√≠cios: \n    O Golden Retriever √© um pet bastante ativo e necessita de exerc√≠cios regulares para mant√™-lo saud√°vel e feliz. Sua energia √© alta e gosta de jogar e brincar, por isso √© recomendado que ele se exercite regularmente durante aproximadamente 1 a 2 horas diariamente. \n\n- Temperamento e Comportamento"
      }
   ]
}
```

3. Caso **N√ÉO** haja pets (nem faces), os elementos contidos em *"faces": [{...}]* recebem valor *None* e o objeto *pets:[...]* fica vazio:

```json 
{
   "url_to_image": "https://sprint08-my-photos.s3.amazonaws.com/Bola.jpg", 
   "created_image": "02-07-2024 00:54:10", 
   "faces": [
      {
         "position": {
            "Height": None, 
            "Left": None, 
            "Top": None, 
            "Width": None
         }, 
         "classified_emotion": None, 
         "classified_emotion_confidence": None
      }
   ],¬†
   "pets":¬†[

   ]
}
```

#### Detectando elementos:

- **Detectando os *pets***: utilizamos a fun√ß√£o `detect_labels`:

```py
def detect_pets(self, bucket, image_name):
   labels_response = self.detect_labels(bucket, image_name)
   animal_characteristics = self.animal_characteristics(labels_response)
   pets = self.pets_labels_treatment(animal_characteristics)
   return pets
```

- Filtramos a resposta da fun√ß√£o para obtermos os **pets**:

```py
def animal_characteristics(self, rekognition_response):
   # Lista de r√≥tulos de poss√≠veis animais de estima√ß√£o
   pet_labels = ["Dog", "Cat", "Bird", "Fish", "Reptile", "Mammal", "Pet"]
   animal_characteristics = []
   for label in rekognition_response["Labels"]:
      for parent in label["Parents"]:
            if parent.get("Name") in pet_labels:
               animal_characteristics.append(label)
   return animal_characteristics
```

- Para obtermos mais **precis√£o** no reconhecimento das ra√ßas dos animais, filtramos "ra√ßas gen√©ricas" do elemento ***breed***.

```py
def _process_pets(self, pet_labels):
   pets = []
   filtered_breeds = ["Animal", "Pet", "Dog", "Bird", "Mammal", "Vertebrate", "Canidae","Canine", "Carnivore", "Terrestrial animal", "Dog breed", "Dog like mammal"]
   unique_breeds = {breed["Name"]: breed for pet in pet_labels["pets"] for breed in pet["labels"] if breed["Name"] not in filtered_breeds}.values()

   # Gera o log das ra√ßas √∫nicas detectadas pelo Rekognition
   logger(f"Ra√ßas √∫nicas: {unique_breeds}")

   # Para cada ra√ßa de animal de estima√ß√£o detectada pelo Rekognition
   for breed in unique_breeds:
      self.bedrock_service.set_pet_breed(breed["Name"])
      response = self.bedrock_service.invoke_model()
      if response["statusCode"] == 200:
            tips = json.loads(response["Dicas"])
      else:
            tips = "Erro ao obter dicas do Bedrock"

      pet_info = {
            "labels": [{"Confidence": breed["Confidence"], "Name": breed["Name"]}],
            "Dicas": tips
      }
      pets.append(pet_info)

   return pets
```

### ‚òÅÔ∏è Inserindo logs no Cloudwatch

Tanto na Parte 1 quanto na Parte 2, inserimos *logs* no **Cloudwatch**. Os *logs* foram formatados da seguinte maneira:

```py
log_event = {
   "logGroupName": log_group_name,
   "logStreamName": log_stream_name,
   "logEvents": [
      {
         "timestamp": int(datetime.datetime.now().timestamp() * 1000),
         "message": json.dumps(message)
      }
   ]
}
```

Criamos duas classifica√ß√µes de *logs*.

1. Quando a requisi√ß√£o for um sucesso:

```py
def logger(message):
    print(message)
    logger_instance.log_message("rekognition-logs", "vision-logs", message)
```

2. Quando houver algum erro:

```py
def error(message):
    print(message)
    logger_instance.log_message("rekognition-logs", "vision-errors", message)
```

### Em resumo, o fluxo da aplica√ß√£o se d√° da seguinte forma:

![Fluxo da Aplica√ß√£o](./assets/arquitetura-base.jpg)

## üìÅ Estrutura do projeto 

#### O projeto foi dividido nos seguintes diret√≥rios, baseando-se no modelo MVC (Model-View-Controller) com devidas adapta√ß√µes:

#### Divis√£o dos diret√≥rios:

- `controller` ‚Üí Realiza a chamada dos *services* (em ./services) criados para gerenciar os servi√ßos AWS, sendo *bucket* na **S3**, reconhecimento no **Amazon Rekognition** e cria√ß√£o de texto no **Amazon Bedrock**.

- `services` ‚Üí Manipulam os servi√ßos AWS obtendo os **metadados** e gera **URL** das imagens no **S3**, detecta faces e r√≥tulos no **Amazon Rekognition**, cria prompt e obtem respostas no **Amazon Bedrock**.

- `utils` ‚Üí Manipula os ***logs*** no **Cloudwatch** e faz *upload* de imagens no **S3**.

#### Outros arquivos importantes:

- `handler.py` ‚Üí Cont√©m as fun√ß√µes que sintetizam a API e define suas rotas. Verifica a sa√∫de da API, recebe a imagem do **S3** e retorna os detalhes do reconhecimento do **Amazon Rekognition**.

- `serverless.yml` ‚Üí Define as pol√≠ticas **IAM** para permitir que as **fun√ß√µes Lambda** acessem os servi√ßos necess√°rios e rotas das requisi√ß√µes que ser√£o usadas no *handler.py*. 

## üìå Como executar o projeto

### Clone o reposit√≥rio

```bash
$ git clone https://github.com/Compass-pb-aws-2024-MARCO/sprints-8-pb-aws-marco.git
```

### Acesse a pasta do projeto no terminal/cmd:

```bash
$ cd sprints-8-pb-aws-marco
```

### Realize um check-out para a branch de desenvolvimento:

```bash
$ git checkout grupo-2
```

### Cerfitique-se ue tem o serverless instalado:

```bash
$ serverless
```

### Caso n√£o estiver, instale poe meio do comando:

```bash
$ npm install -g serverless
```

### Instale os plugins do serverless:

```bash
$ npm install serverless-python-requirements serverless-dotenv-plugin
```

### Configure as credenciais da aws:

```bash
$ aws configure
```

### Fa√ßa login no serverless:

```bash
$ serverless login
```

### Acesse a pasta visao-computacional:

```bash
$ cd visao-computacional
```

### Execute o seguinte comando para realizar o deploy:
```bash
$ serverless deploy
```

## üîó Links de Teste

### Endpoints:

üî∏ **GET** - https://fbpdfs3097.execute-api.us-east-1.amazonaws.com/

üî∏ **GET** - https://fbpdfs3097.execute-api.us-east-1.amazonaws.com/v1

üî∏ **GET** - https://fbpdfs3097.execute-api.us-east-1.amazonaws.com/v2

üîπ **POST** - https://fbpdfs3097.execute-api.us-east-1.amazonaws.com/v1/vision

üîπ **POST** - https://fbpdfs3097.execute-api.us-east-1.amazonaws.com/v2/vision


## üïµÔ∏è Dificuldades Encontradas

### ‚öô Dificuldades T√©cnicas

O Rekognition retorna diversos dados, incluindo informa√ß√µes que **n√£o eram necess√°rias** para nosso uso, referidas como "ra√ßas gen√©ricas". Conseguimos solucionar o problema [aplicando filtros](#detectando-elementos-1) aos dados. No entanto, essa solu√ß√£o s√≥ foi alcan√ßada ap√≥s a an√°lise de v√°rios exemplos de retorno e uma **extensa** pesquisa na documenta√ß√£o do Rekognition sobre o t√≥pico, especialmente na [API Vision V2 (Emo√ß√µes + Pets)](#-parte-2---emo√ß√µes-e-pets).

Outra dificuldade que enfrentamos foi o **timeout** ao configurarmos o *Bedrock*. O API Gateway possui um limite de 30 segundos para requisi√ß√µes HTTP, enquanto o *Bedrock* levava quase **5 minutos** para retornar os dados, mesmo para apenas um pet. Resolvemos esse problema realizando algumas modifica√ß√µes no c√≥digo, ajustando os atributos **maxTokenCount**, **temperature** e **topP** no arquivo `bedrock_services.py`.

```py
def generate_request_body(self):
   request_body = {
      "inputText": self.create_prompt(),
      "textGenerationConfig": {
            "maxTokenCount": 128,
            # temperature:  aleatoriedade na gera√ß√£o de texto
            "temperature": 0.7,
            # topP:  tokens que comp√µem o top p% da probabilidade cumulativa
            "topP": 0.9
      },
   }
   return json.dumps(request_body)
```

### üìù Dificuldades de Organiza√ß√£o

<!-- ... -->
